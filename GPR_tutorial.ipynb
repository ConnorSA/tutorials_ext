{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPR-tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ConnorSA/tutorials_ext/blob/master/GPR_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# HOMO energy prediction with Gaussian process regression\n",
        "\n",
        "Now let's reproduce the KRR results from the previous notebook with another kernel-based model, Gaussian Process regression (GPR)."
      ],
      "metadata": {
        "id": "FomxfBKMCkay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.gaussian_process import GaussianProcessRegressor\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.gaussian_process.kernels import ConstantKernel\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.sparse import load_npz\n",
        "import math, random"
      ],
      "metadata": {
        "id": "pbptnkS_DCr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load and visualize data \n",
        "\n",
        "Once again, we load the data. Reminder: the input data x is an array that contains all 7k molecules of the QM7 dataset, represented by their Coulomb matrices, which were computed with the [Dscribe](https://www.sciencedirect.com/science/article/pii/S0010465519303042?via%3Dihub) package. The output data y is a list that contains the corresponding (pre-computed) HOMO energies."
      ],
      "metadata": {
        "id": "Eg-T8HiKDL_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/fullmetalfelix/ML-CSC-tutorial/raw/master/data/qm7/cm.npz\n",
        "!wget https://raw.githubusercontent.com/fullmetalfelix/ML-CSC-tutorial/master/data/qm7/HOMO.txt\n",
        "\n",
        "x = load_npz(\"cm.npz\").toarray()\n",
        "y = np.genfromtxt(\"HOMO.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rp7gvHe4DR5p",
        "outputId": "06605849-6a63-484e-dd64-ec87db63dd7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-10 08:01:14--  https://github.com/fullmetalfelix/ML-CSC-tutorial/raw/master/data/qm7/cm.npz\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/fullmetalfelix/ML-CSC-tutorial/master/data/qm7/cm.npz [following]\n",
            "--2022-05-10 08:01:14--  https://raw.githubusercontent.com/fullmetalfelix/ML-CSC-tutorial/master/data/qm7/cm.npz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3638980 (3.5M) [application/octet-stream]\n",
            "Saving to: ‘cm.npz.2’\n",
            "\n",
            "cm.npz.2            100%[===================>]   3.47M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2022-05-10 08:01:14 (52.3 MB/s) - ‘cm.npz.2’ saved [3638980/3638980]\n",
            "\n",
            "--2022-05-10 08:01:14--  https://raw.githubusercontent.com/fullmetalfelix/ML-CSC-tutorial/master/data/qm7/HOMO.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 54610 (53K) [text/plain]\n",
            "Saving to: ‘HOMO.txt.2’\n",
            "\n",
            "HOMO.txt.2          100%[===================>]  53.33K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2022-05-10 08:01:14 (5.14 MB/s) - ‘HOMO.txt.2’ saved [54610/54610]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, shuffle and divide the dataset into test-train split."
      ],
      "metadata": {
        "id": "oT4wRikhDjBZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## shuffle the data\n",
        "\n",
        "c = list(zip(x, y))\n",
        "random.shuffle(c)\n",
        "\n",
        "x, y = zip(*c)\n",
        "\n",
        "x = np.array(x)\n",
        "y = np.array(y)\n",
        "\n",
        "# decide how many samples to take from the database for training and testing\n",
        "n_train = 1000\n",
        "n_test = 1000\n",
        "\n",
        "# split data in training and test\n",
        "# take first n_train molecules for training\n",
        "x_train  = x[0:n_train] \n",
        "y_train = y[0:n_train]\n",
        "\n",
        "# take the next n_test data for testing\n",
        "x_test = x[n_train:n_train + n_test]\n",
        "y_test = y[n_train:n_train + n_test]"
      ],
      "metadata": {
        "id": "hwNT1VEgDoJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Kernel setup\n",
        "\n",
        "The first step in GPR is to define a kernel. In this example, we'll use the Gaussian kernel (also called the squared exponential SE or the radial basis function RBF kernel). This will make the fitting exactly compatible with the KRR example we did earlier.\n",
        "\n",
        "Please note that scikit-learn package [defines the RBF kernel](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.RBF.html#sklearn.gaussian_process.kernels.RBF) as the exponential function only, without the scaling factor multiplying it. This is why we will multiply it with a [Constant kernel C](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.kernels.ConstantKernel.html?highlight=constantkernel#sklearn.gaussian_process.kernels.ConstantKernel), to obtain the standard experssion for the Gaussian, which is used in other packages. Kernel development is an active field of research in GPR. The product or sum of kernels is another valid kernel.\n",
        "\n",
        "## Kernel hyperparameters\n",
        "Our composite C*RBF kernel has a couple of parameters: the constant value (for C) and the Gaussian lengthscale (for RBF). These are fitted in an automated way alongside with model fitting, by maximising the logarithm of the marginal likelihood in the hyperparameter search space. In practice, this translates into a bounded search for each hyperparameter. \n",
        "\n",
        "For each parameter search, we need to define the initial value (to start the search) and the lower and upper bounds. The bounds are often defined as a factor (e.g. x=1e2) dividing/multiplying the initial value.\n",
        "\n",
        "**PRO TIP:** when approaching a new dataset, keep bounds large (x=1e4) until you see where the hyperparameters are converging, then adjust the starting position and reduce the x to 100, which makes the search faster. "
      ],
      "metadata": {
        "id": "NdWmTKtKDupt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the initial values of hyperparameters and the search bounds\n",
        "const, bound, length = 4, 1e2, 100\n",
        "\n",
        "# Construct the kernel\n",
        "kernel = ConstantKernel(\n",
        "        constant_value=const,\n",
        "        # hyperparameter bounded search: lower bound, upper bound\n",
        "        constant_value_bounds=(const * 1.0 / bound, const * bound),) \\\n",
        "        * RBF(length_scale=length,\n",
        "        # hyperparameter bounded search: lower bound, upper bound\n",
        "        length_scale_bounds=(length * 1.0 / bound, length * bound),)"
      ],
      "metadata": {
        "id": "Nz_Fxd3ODysM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPR model\n",
        "\n",
        "Given the kernel K=C*RBF above, let's proceed to construct the [GPR model](https://scikit-learn.org/stable/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.html?highlight=gaussianprocessregressor#sklearn.gaussian_process.GaussianProcessRegressor). The main entries are the kernel K and the data noise parameter alpha. Alpha represent a native measure of data variation (usually very small in computations) and is added to the diagonal of the K during model fitting. Very small alpha values (1e-12) can lead to unstable algorithm performance (matrix inversion), so even if you have no noise, it is recommended to set at least alpha to 1e-8, if not larger.\n",
        "\n",
        "Other GPR model options are related to the fitting procedure. The model may perform better/worse if you normalize your data, please check when starting with a new dataset. Also: the hyperparameter search proceeds via local minimisers from the initial hyperparameter value supplied in the kernel, so it's advised to perform several random restarts (at least 2) to check if an even better hyperparameter solution can be found. Please check this when starting with a new dataset, in case the initial settings are not optimal. \n",
        "\n",
        "**PRO TIP**: When starting with a new dataset, the initial hyperparameter values may be suboptimal, so please use several restarts and check optimal solutions. Then you can supply a good starting location for hyperparamers and reduce (costly) restarts. Similarly with the noise parameter alpha: with new data, it is recommended to perform an exploratory grid search, slowly increasing alpha from 1e-8 (very small) to 1e-1 (too large). The optimal value of alpha produces the best model accuracy and prevents overfitting."
      ],
      "metadata": {
        "id": "ZJkZI5syE8dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpr = GaussianProcessRegressor(\n",
        "      kernel=kernel,   # K=C*RBF\n",
        "      alpha=0.0001,    # data noise\n",
        "      normalize_y=True,\n",
        "      n_restarts_optimizer=2, # random restarts for the hyperparameter search\n",
        "      random_state=1234)           "
      ],
      "metadata": {
        "id": "ROehGWncE_re"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model training\n",
        "\n",
        "Next, let's fit the model on the training set data. After the fit, kernel parameters will have changed to optimal values. Please inspect them and record the values. NOTE: different values of noise can lead to different optimal hyperparameter solutions."
      ],
      "metadata": {
        "id": "VMOwGzQIFWxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpr.fit(x_train, y_train)\n",
        "    \n",
        "# This prints an exhaustive list of all settings relevant to GPR\n",
        "print(f\"trained params : {gpr.get_params()}\")\n",
        "\n",
        "# This prints the optimal hyperparameters of the kernel\n",
        "print(f\"trained params : {gpr.kernel_}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFF9lsHIFZgN",
        "outputId": "ea328a21-ef8a-4258-b2a0-3d359a031cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trained params : {'alpha': 0.0001, 'copy_X_train': True, 'kernel__k1': 2**2, 'kernel__k2': RBF(length_scale=100), 'kernel__k1__constant_value': 4, 'kernel__k1__constant_value_bounds': (0.04, 400.0), 'kernel__k2__length_scale': 100, 'kernel__k2__length_scale_bounds': (1.0, 10000.0), 'kernel': 2**2 * RBF(length_scale=100), 'n_restarts_optimizer': 2, 'normalize_y': True, 'optimizer': 'fmin_l_bfgs_b', 'random_state': 1234}\n",
            "trained params : 1.18**2 * RBF(length_scale=27.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating results\n",
        "\n",
        "There are two key results from a GPR fit: GP posterior mean *y_mean* and the GP posterior variance (*y_std*)^2 (measure of confidence on the mean). The GP posterior mean is the data prediction. We can evaluate these for each data entry in our test set to compute the mean absolute error and evaluate model performance: the perfomance seems to be similar to the KRR model.  "
      ],
      "metadata": {
        "id": "CuHvto-0NSbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scikit-learn automatically takes the best hyperparameter combination from the model training.\n",
        "y_mean, y_std = gpr.predict(x_test, return_std=True)  \n",
        "\n",
        "mae = (np.abs(y_mean - y_test)).mean()\n",
        "print(\"Mean absolute error on test set: %0.3f eV\" %mae)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UETBYLoxIuBf",
        "outputId": "6aa074e6-7c45-4e7f-a7dd-0e92c6ea62ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean absolute error on test set: 0.298 eV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is very useful to obtain GPR estimates on where the model is uncertain. Let's visualise the distribution of predictive uncertainties across the entire test set. Here, overall, the model is relatively uncertain (average uncertainties > average MAE), indicating that more data is needed for better quality predictions.\n"
      ],
      "metadata": {
        "id": "aUTG-LzyIPoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.hist(y_std, bins=20, density=False, facecolor='purple')\n",
        "plt.xlabel(\"Posterior variance [eV]\")\n",
        "plt.ylabel(\"Number of molecules\")\n",
        "plt.title(\"Distribution of GP posterior stdev\")\n",
        "plt.show()\n",
        "\n",
        "## mean value of distribution\n",
        "print(\"Mean value of GP posterior standard deviation on testset predictions: %0.2f eV\" %np.mean(y_std))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "x1ig5_e4HVhW",
        "outputId": "91f8bd54-d0d3-4ac9-d1cf-5c601e5ee112"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean value of GP posterior standard deviation on testset predictions: 0.41 eV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exercises**\n",
        "\n",
        "### 1. Noise\n",
        "\n",
        "Take a note of the current MAE and try adjusting the noise by a factor of 10 or 100 lower or higher. How does this change the MAE and the average standard deviation? Which alpha noise setting produces the lowest MAE for this dataset size? "
      ],
      "metadata": {
        "id": "siG6QkTVMPTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "quRIugIWMU6A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Hyperparameter search\n",
        "\n",
        "Check fitted values for hyperparameters against the values of the hyperparameter bounds - if the final result is the same as the bound, they need to be adjusted. Also, try switching off the restarts, and increasing the no. of restarts - do the final hyperparameters change, and how does this affect the MAE? "
      ],
      "metadata": {
        "id": "TxcunE7BMXYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "P9VgDEHaM2BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Initial hyperparameters\n",
        "\n",
        "Try varing the initial hyperparameters by a factor of 10 (larger and smaller): how does this change the final hyperparameters and the MAE?"
      ],
      "metadata": {
        "id": "isBNjEYAM2QW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "USAntW5QNF0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Dataset size\n",
        "\n",
        "Having found the optimal settings for the GPR (noise, hyperparameter initial values, bounds, etc.), try increasing the training set size and check that the MAE is reduced. How does this affect the average GP model standard deviation?"
      ],
      "metadata": {
        "id": "yijcuOwpQt8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZOAkJeoHREbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "VujPNnNjRFKk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}